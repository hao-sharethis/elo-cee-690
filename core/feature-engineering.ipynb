{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Feature Engineering is the key.\n",
    "\n",
    "  \n",
    "reference:  \n",
    "https://www.kaggle.com/mjbahmani/statistical-analysis-for-elo  \n",
    "https://www.kaggle.com/c/elo-merchant-category-recommendation/discussion/82055  \n",
    "https://www.kaggle.com/chauhuynh/my-first-kernel-3-699  \n",
    "https://www.kaggle.com/fabiendaniel/elo-world  \n",
    "https://www.kaggle.com/raddar/target-true-meaning-revealed  \n",
    "https://www.kaggle.com/c/elo-merchant-category-recommendation/discussion/82036#479038  \n",
    "https://machinelearningmastery.com/basic-feature-engineering-time-series-data-python/  \n",
    "https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering this is really helpfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data_Dictionary.xlsx', 'new_merchant_transactions.csv', 'test.csv', 'merchants.csv', 'historical_transactions.csv', 'train.csv', 'load_data.py', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(4590)\n",
    "\n",
    "print(os.listdir(\"../data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "merchants = pd.read_csv('../data/merchants.csv')\n",
    "historical_transactions = pd.read_csv('../data/historical_transactions.csv')\n",
    "new_transactions = pd.read_csv('../data/new_merchant_transactions.csv')\n",
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "print('...loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Null Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set NA data first_active_month    0\n",
      "card_id               0\n",
      "feature_1             0\n",
      "feature_2             0\n",
      "feature_3             0\n",
      "target                0\n",
      "dtype: int64\n",
      "test set NA data first_active_month    1\n",
      "card_id               0\n",
      "feature_1             0\n",
      "feature_2             0\n",
      "feature_3             0\n",
      "dtype: int64\n",
      "new transaction set NA data authorized_flag              0\n",
      "card_id                      0\n",
      "city_id                      0\n",
      "category_1                   0\n",
      "installments                 0\n",
      "category_3               55922\n",
      "merchant_category_id         0\n",
      "merchant_id              26216\n",
      "month_lag                    0\n",
      "purchase_amount              0\n",
      "purchase_date                0\n",
      "category_2              111745\n",
      "state_id                     0\n",
      "subsector_id                 0\n",
      "dtype: int64\n",
      "historical transaction set NA data authorized_flag               0\n",
      "card_id                       0\n",
      "city_id                       0\n",
      "category_1                    0\n",
      "installments                  0\n",
      "category_3               178159\n",
      "merchant_category_id          0\n",
      "merchant_id              138481\n",
      "month_lag                     0\n",
      "purchase_amount               0\n",
      "purchase_date                 0\n",
      "category_2              2652864\n",
      "state_id                      0\n",
      "subsector_id                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# view NA data\n",
    "print(\"train set NA data {}\".format(train.isna().sum()))\n",
    "print(\"test set NA data {}\".format(test.isna().sum()))\n",
    "print(\"new transaction set NA data {}\".format(new_transactions.isna().sum()))\n",
    "print(\"historical transaction set NA data {}\".format(historical_transactions.isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NA data, be careful\n",
    "train = train.dropna()\n",
    "\n",
    "# fill the NA data, is it going to have a bad influence on our model?\n",
    "for df in [historical_transactions, new_transactions]:\n",
    "    df['category_3'].fillna('A', inplace=True)\n",
    "    df['category_2'].fillna(1.0, inplace=True)\n",
    "    df['merchant_id'].fillna('M_ID_00a6ca8a8a', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "\n",
    "Manual feature engineering can be a tedious process (which is why we use automated feature engineering with featuretools!) and often relies on domain expertise. I will concentrate of getting as much info as possible into the final training dataframe. The idea is that the model will then pick up on which features are important rather than us having to decide that. Basically, our approach is to make as many features as possible and then give them all to the model to use! Later, we can perform feature reduction using the feature importances from the model or other techniques such as PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first_active_month', 'card_id', 'feature_1', 'feature_2', 'feature_3', 'target']\n",
      "['first_active_month', 'card_id', 'feature_1', 'feature_2', 'feature_3']\n",
      "['authorized_flag', 'card_id', 'city_id', 'category_1', 'installments', 'category_3', 'merchant_category_id', 'merchant_id', 'month_lag', 'purchase_amount', 'purchase_date', 'category_2', 'state_id', 'subsector_id']\n",
      "['authorized_flag', 'card_id', 'city_id', 'category_1', 'installments', 'category_3', 'merchant_category_id', 'merchant_id', 'month_lag', 'purchase_amount', 'purchase_date', 'category_2', 'state_id', 'subsector_id']\n"
     ]
    }
   ],
   "source": [
    "# print all current features\n",
    "print(list(train))\n",
    "print(list(test))\n",
    "print(list(historical_transactions))\n",
    "print(list(new_transactions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to understand the feature now.\n",
    "1. the train dataset, we can see that it has card_id, this should be the unique id we can use for user profile, and group or aggregate the data w.r.t this feature. the feature_# in the data_dictionary descibed as Anonymized card categorical feature, we need to understand it later.\n",
    "2. historical and new transactions. these two dataset have similar data structure.  \n",
    "    a. 'purchase_date': max','min', require feature extraction.\n",
    "        - 'month','hour','weekofyear','dayofweek','year', require no further process\n",
    "        - 'weekend': 'sum', 'mean'\n",
    "    b. 'merchant_id', 'merchant_category_id', 'subsector_id' need no more process.  \n",
    "    c. 'purchase_amount': 'sum','max','min','mean','var'.  \n",
    "    d. 'month_lag': 'max','min','mean','var'  \n",
    "    e. 'month_diff': 'mean'  \n",
    "    f. 'authorized_flag': 'sum, 'mean'  \n",
    "    g. 'category_1': 'sum', 'mean'  \n",
    "    h. 'category_2': 'mean'  \n",
    "    i. 'category_3': 'mean'  \n",
    "    j. 'card_id': 'size'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function, create new column\n",
    "def create_column(prefix, aggs):\n",
    "    return [prefix + '_' + key + '_' + agg for key in aggs.keys() for agg in aggs[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## main data preprocessing block\n",
    "\n",
    "# 1. One important feature here is purchase_date feature, we need to extract it into year, month,\n",
    "# week of year, day of week, weekend, hour\n",
    "# 2. get time difference to today which \n",
    "# 3. normalize binary data to 1/0 int\n",
    "\n",
    "\n",
    "for df in [historical_transactions, new_transactions]:\n",
    "    \n",
    "    # date conversion\n",
    "    df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "    df['year'] = df['purchase_date'].dt.year\n",
    "    df['weekofyear'] = df['purchase_date'].dt.weekofyear\n",
    "    df['month'] = df['purchase_date'].dt.month\n",
    "    df['dayofweek'] = df['purchase_date'].dt.dayofweek\n",
    "    df['weekend'] = (df['purchase_date'].dt.dayofweek >= 5).astype(int) # 0-5 week day\n",
    "    df['hour'] = df['purchase_date'].dt.hour\n",
    "    \n",
    "    ## time difference\n",
    "    # https://www.kaggle.com/c/elo-merchant-category-recommendation/discussion/73244\n",
    "    df['month_diff'] = ((datetime.datetime.today() - df['purchase_date']).dt.days)//30\n",
    "    df['month_diff'] += df['month_lag']\n",
    "    \n",
    "    # normalization\n",
    "    # TODO still not well done here\n",
    "    df['authorized_flag'] = df['authorized_flag'].map({'Y': 1, 'N': 0})\n",
    "    df['category_1'] = df['category_1'].map({'Y': 1, 'N': 0})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorized_flag</th>\n",
       "      <th>card_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>category_1</th>\n",
       "      <th>installments</th>\n",
       "      <th>category_3</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>month_lag</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>...</th>\n",
       "      <th>category_2</th>\n",
       "      <th>state_id</th>\n",
       "      <th>subsector_id</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>weekend</th>\n",
       "      <th>hour</th>\n",
       "      <th>month_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_415bb3a509</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>307</td>\n",
       "      <td>M_ID_b0c793002c</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.557574</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_415bb3a509</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>307</td>\n",
       "      <td>M_ID_88920c89e8</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.569580</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_415bb3a509</td>\n",
       "      <td>330</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>507</td>\n",
       "      <td>M_ID_ad5237ef6b</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.551037</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>2018</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_415bb3a509</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>661</td>\n",
       "      <td>M_ID_9e84cda3b1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.671925</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_ef55cf8d4b</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>166</td>\n",
       "      <td>M_ID_3c86fa3831</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.659904</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>29</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   authorized_flag          card_id  city_id  category_1  installments  \\\n",
       "0                1  C_ID_415bb3a509      107           0             1   \n",
       "1                1  C_ID_415bb3a509      140           0             1   \n",
       "2                1  C_ID_415bb3a509      330           0             1   \n",
       "3                1  C_ID_415bb3a509       -1           1             1   \n",
       "4                1  C_ID_ef55cf8d4b       -1           1             1   \n",
       "\n",
       "  category_3  merchant_category_id      merchant_id  month_lag  \\\n",
       "0          B                   307  M_ID_b0c793002c          1   \n",
       "1          B                   307  M_ID_88920c89e8          1   \n",
       "2          B                   507  M_ID_ad5237ef6b          2   \n",
       "3          B                   661  M_ID_9e84cda3b1          1   \n",
       "4          B                   166  M_ID_3c86fa3831          1   \n",
       "\n",
       "   purchase_amount  ... category_2  state_id  subsector_id  year  weekofyear  \\\n",
       "0        -0.557574  ...        1.0         9            19  2018          10   \n",
       "1        -0.569580  ...        1.0         9            19  2018          12   \n",
       "2        -0.551037  ...        1.0         9            14  2018          17   \n",
       "3        -0.671925  ...        1.0        -1             8  2018          10   \n",
       "4        -0.659904  ...        1.0        -1            29  2018          12   \n",
       "\n",
       "   month  dayofweek  weekend  hour  month_diff  \n",
       "0      3          6        1    14          14  \n",
       "1      3          0        0    18          13  \n",
       "2      4          3        0    14          13  \n",
       "3      3          2        0     9          14  \n",
       "4      3          3        0    21          13  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature aggregation\n",
    "`groupby`: group a dataframe by a column. In this case we will group by the `card_id`.  \n",
    "`agg`: perform a calculation on the grouped data such as taking the `mean` of columns. We can either call the function directly (grouped_df.mean()) or use the agg function together with a list of transforms (`grouped_df.agg([mean, max, min, sum])`)  \n",
    "`merge`: match the aggregated statistics to the appropriate client. We need to merge the original training data with the calculated stats on the `card_id` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create aggregation columns (features)\n",
    "aggs = {}\n",
    "for col in ['month','hour','weekofyear','dayofweek','year','subsector_id','merchant_id','merchant_category_id']:\n",
    "    aggs[col] = ['nunique']\n",
    "    \n",
    "aggs['purchase_amount'] = ['sum','max','min','mean','var']\n",
    "aggs['installments'] = ['sum','max','min','mean','var']\n",
    "aggs['purchase_date'] = ['max','min']\n",
    "aggs['month_lag'] = ['max','min','mean','var']\n",
    "aggs['month_diff'] = ['mean']\n",
    "aggs['authorized_flag'] = ['sum', 'mean']\n",
    "aggs['weekend'] = ['sum', 'mean']\n",
    "aggs['card_id'] = ['size']\n",
    "\n",
    "aggs['category_1'] = ['sum', 'mean']\n",
    "\n",
    "for col in ['category_2','category_3']:\n",
    "    aggs[col+'_mean'] = ['mean'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'month': ['nunique'],\n",
       " 'hour': ['nunique'],\n",
       " 'weekofyear': ['nunique'],\n",
       " 'dayofweek': ['nunique'],\n",
       " 'year': ['nunique'],\n",
       " 'subsector_id': ['nunique'],\n",
       " 'merchant_id': ['nunique'],\n",
       " 'merchant_category_id': ['nunique'],\n",
       " 'purchase_amount': ['sum', 'max', 'min', 'mean', 'var'],\n",
       " 'installments': ['sum', 'max', 'min', 'mean', 'var'],\n",
       " 'purchase_date': ['max', 'min'],\n",
       " 'month_lag': ['max', 'min', 'mean', 'var'],\n",
       " 'month_diff': ['mean'],\n",
       " 'authorized_flag': ['sum', 'mean'],\n",
       " 'weekend': ['sum', 'mean'],\n",
       " 'card_id': ['size'],\n",
       " 'category_1': ['sum', 'mean'],\n",
       " 'category_2_mean': ['mean'],\n",
       " 'category_3_mean': ['mean']}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# historical transaction feature engineering\n",
    "#\n",
    "# append a column to historical transactions first\n",
    "for col in ['category_2', 'category_3']:\n",
    "     historical_transactions[col + '_mean'] = \\\n",
    "        historical_transactions.groupby([col])['purchase_amount'].transform('mean')\n",
    "\n",
    "# historical transaction features\n",
    "hist_columns = create_column('hist', aggs)\n",
    "\n",
    "hist_trans_agg = historical_transactions.groupby('card_id').agg(aggs)\n",
    "hist_trans_agg.columns = hist_columns\n",
    "hist_trans_agg.reset_index(drop=False, inplace=False)\n",
    "hist_trans_agg['hist_purchase_date_diff'] = \\\n",
    "    (hist_trans_agg['hist_purchase_date_max'] - hist_trans_agg['hist_purchase_date_min']).dt.days\n",
    "hist_trans_agg['hist_purchase_date_average'] = \\\n",
    "    (hist_trans_agg['hist_purchase_date_diff']) / hist_trans_agg['hist_card_id_size']\n",
    "hist_trans_agg['hist_purchase_date_uptonow'] = \\\n",
    "    (datetime.datetime.today() - hist_trans_agg['hist_purchase_date_max']).dt.days\n",
    "\n",
    "# merge into train and test dataset\n",
    "train = train.merge(hist_trans_agg, on='card_id', how='left')\n",
    "test = test.merge(hist_trans_agg, on='card_id', how='left')\n",
    "\n",
    "# gc collection, save memory\n",
    "del hist_trans_agg;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new transaction feature engineering\n",
    "#\n",
    "# append a column to new transactions first\n",
    "for col in ['category_2', 'category_3']:\n",
    "     new_transactions[col + '_mean'] = \\\n",
    "        new_transactions.groupby([col])['purchase_amount'].transform('mean')\n",
    "\n",
    "# new transaction features\n",
    "new_columns = create_column('new', aggs)\n",
    "\n",
    "new_trans_agg = new_transactions.groupby('card_id').agg(aggs)\n",
    "new_trans_agg.columns = new_columns\n",
    "new_trans_agg.reset_index(drop=False, inplace=False)\n",
    "new_trans_agg['new_purchase_date_diff'] = \\\n",
    "    (new_trans_agg['new_purchase_date_max'] - new_trans_agg['new_purchase_date_min']).dt.days\n",
    "new_trans_agg['new_purchase_date_average'] = \\\n",
    "    (new_trans_agg['new_purchase_date_diff']) / new_trans_agg['new_card_id_size']\n",
    "new_trans_agg['new_purchase_date_uptonow'] = \\\n",
    "    (datetime.datetime.today() - new_trans_agg['new_purchase_date_max']).dt.days\n",
    "\n",
    "# merge into train and test dataset\n",
    "train = train.merge(new_trans_agg, on='card_id', how='left')\n",
    "test = test.merge(new_trans_agg, on='card_id', how='left')\n",
    "\n",
    "# gc collection\n",
    "del new_trans_agg;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gc collection\n",
    "del historical_transactions;gc.collect()\n",
    "del new_transactions;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199710\n",
       "1      2207\n",
       "Name: outliers, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outliers\n",
    "train['outliers'] = 0\n",
    "train.loc[train['target'] < -30, 'outliers'] = 1\n",
    "train['outliers'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test dataset feature engineering\n",
    "for df in [train, test]:\n",
    "    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "    df['dayofweek'] = df['first_active_month'].dt.dayofweek\n",
    "    df['weekofyear'] = df['first_active_month'].dt.weekofyear\n",
    "    df['month'] = df['first_active_month'].dt.month\n",
    "    df['elapsed_time'] = (datetime.datetime.today() - df['first_active_month']).dt.days\n",
    "    df['hist_first_buy'] = (df['hist_purchase_date_min'] - df['first_active_month']).dt.days\n",
    "    df['new_first_buy'] = (df['new_purchase_date_min'] - df['first_active_month']).dt.days\n",
    "    for f in ['hist_purchase_date_max','hist_purchase_date_min','new_purchase_date_max',\\\n",
    "                     'new_purchase_date_min']:\n",
    "        df[f] = df[f].astype(np.int64) * 1e-9\n",
    "    df['card_id_total'] = df['hist_card_id_size'] + df['new_card_id_size']\n",
    "    df['purchase_amount_total'] = df['new_purchase_amount_sum'] + df['hist_purchase_amount_sum']\n",
    "\n",
    "for f in ['feature_1','feature_2','feature_3']:\n",
    "    order_label = train.groupby([f])['outliers'].mean()\n",
    "    train[f] = train[f].map(order_label)\n",
    "    test[f] = test[f].map(order_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>hist_month_nunique</th>\n",
       "      <th>hist_hour_nunique</th>\n",
       "      <th>hist_weekofyear_nunique</th>\n",
       "      <th>hist_dayofweek_nunique</th>\n",
       "      <th>...</th>\n",
       "      <th>new_purchase_date_uptonow</th>\n",
       "      <th>outliers</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>month</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>hist_first_buy</th>\n",
       "      <th>new_first_buy</th>\n",
       "      <th>card_id_total</th>\n",
       "      <th>purchase_amount_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>0.013145</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.011428</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>675</td>\n",
       "      <td>26</td>\n",
       "      <td>277.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>-179.212942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>0.010712</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>373.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>826</td>\n",
       "      <td>5</td>\n",
       "      <td>396.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>-214.362071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>979</td>\n",
       "      <td>163</td>\n",
       "      <td>635.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-29.867717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>0.010712</td>\n",
       "      <td>0.014166</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>583</td>\n",
       "      <td>25</td>\n",
       "      <td>187.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-54.145736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>0.008058</td>\n",
       "      <td>0.014166</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>343.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>522</td>\n",
       "      <td>11</td>\n",
       "      <td>121.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>-68.613893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3  \\\n",
       "0         2017-06-01  C_ID_92a2005557   0.013145   0.008752   0.011428   \n",
       "1         2017-01-01  C_ID_3d0044924f   0.010712   0.011385   0.010283   \n",
       "2         2016-08-01  C_ID_d639edf6cd   0.010610   0.008752   0.010283   \n",
       "3         2017-09-01  C_ID_186d6a6901   0.010712   0.014166   0.010283   \n",
       "4         2017-11-01  C_ID_cdbd2c0db2   0.008058   0.014166   0.010283   \n",
       "\n",
       "     target  hist_month_nunique  hist_hour_nunique  hist_weekofyear_nunique  \\\n",
       "0 -0.820283                   9                 23                       35   \n",
       "1  0.392913                  12                 24                       50   \n",
       "2  0.688056                  10                 14                       22   \n",
       "3  0.142495                   6                 16                       20   \n",
       "4 -0.159749                   4                 22                       17   \n",
       "\n",
       "   hist_dayofweek_nunique  ...  new_purchase_date_uptonow  outliers  \\\n",
       "0                       7  ...                      343.0         0   \n",
       "1                       7  ...                      373.0         0   \n",
       "2                       7  ...                      343.0         0   \n",
       "3                       7  ...                      354.0         0   \n",
       "4                       7  ...                      343.0         0   \n",
       "\n",
       "   dayofweek  weekofyear  month  elapsed_time  hist_first_buy  new_first_buy  \\\n",
       "0          3          22      6           675              26          277.0   \n",
       "1          6          52      1           826               5          396.0   \n",
       "2          0          31      8           979             163          635.0   \n",
       "3          4          35      9           583              25          187.0   \n",
       "4          2          44     11           522              11          121.0   \n",
       "\n",
       "   card_id_total  purchase_amount_total  \n",
       "0          283.0            -179.212942  \n",
       "1          356.0            -214.362071  \n",
       "2           44.0             -29.867717  \n",
       "3           84.0             -54.145736  \n",
       "4          169.0             -68.613893  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the modeling now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LightGBM to evaluate features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
